{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Overfitting, Underfitting, Cross Validation, Polynomial Regression",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BarisSari/Algorithms/blob/master/Overfitting%2C_Underfitting%2C_Cross_Validation%2C_Polynomial_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wWqCEbuQCom",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWLU0gh2Qja8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "diabetes = datasets.load_diabetes() # load data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZua7pa9Qo8n",
        "colab_type": "code",
        "outputId": "499f4681-e2b5-4aca-e61c-c605cb95e36e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "diabetes.data.shape # feature matrix shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(442, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IS0o44xHQspS",
        "colab_type": "code",
        "outputId": "f72356ce-b8a3-4dc9-fc5d-f536d5fa2a07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "diabetes.target.shape # target vector shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(442,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkrZLAq_QvFt",
        "colab_type": "code",
        "outputId": "71e4f200-3cfe-4fe7-ea30-b3d802a79688",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "diabetes.feature_names # column names"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRDfyfOT_Jv8",
        "colab_type": "text"
      },
      "source": [
        "When training on data, we don't want to use all of our data to train the model, because we want to section off some data for us to test the models performance. The reason why we can't just use the data the model was trained on to judge the model's performance is because that would give an overly optimistic view on how the model is doing. It's like giving you the exact same test to practice on as the one you will take on test day. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "898xTGU4Qy_L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(diabetes.data, diabetes.target, test_size=0.2, random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0vxMs3ZACUx",
        "colab_type": "text"
      },
      "source": [
        "There are three steps to getting a model up and running in sklearn. \n",
        "1. Set up the model\n",
        "2. Fit the model \n",
        "3. Check the score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faOiMumaQ2Gg",
        "colab_type": "code",
        "outputId": "3e6f0552-be8e-40d5-ec9d-ff977a61847b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 1. Set up the model\n",
        "model = LinearRegression()\n",
        "# 2. Use fit\n",
        "model.fit(X_train, y_train)\n",
        "# 3. Check the score\n",
        "print(model.score(X_test, y_test))\n",
        "model_final = model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.33222203269065176\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyLlVttozVZ3",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://www.statisticshowto.datasciencecentral.com/wp-content/uploads/2016/10/root-mean-square-error.png)\n",
        "\n",
        "This is the loss function so that the model can see how well it is predicting and adjust."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDvwWdIVQ4wZ",
        "colab_type": "code",
        "outputId": "fa2f9887-6a3b-4b81-ab37-4d406f2f0468",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "model.coef_ # Get the coefficients, beta"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ -35.55683674, -243.1692265 ,  562.75404632,  305.47203008,\n",
              "       -662.78772128,  324.27527477,   24.78193291,  170.33056502,\n",
              "        731.67810787,   43.02846824])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JP0JU0o-RA98",
        "colab_type": "code",
        "outputId": "bef3bf55-e001-409c-a705-87d88f451312",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.intercept_ # Get the intercept, c"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "152.5381335195406"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dc02JoQ3RBnE",
        "colab_type": "code",
        "outputId": "197a0b12-eb0e-4892-8e9d-7924b25fe287",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "model.predict(X_test) # Predict unkown data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([238.47145247, 248.93170646, 164.05404165, 120.30794355,\n",
              "       187.42422054, 259.04865002, 113.55556372, 188.07597044,\n",
              "       149.49663441, 236.01099949, 172.24629506, 178.88073764,\n",
              "       109.15751983,  92.13508975, 243.33042043,  87.356971  ,\n",
              "       155.72606406,  66.99073989, 100.42610442, 218.09422877,\n",
              "       196.66287912, 161.29832968, 161.70779605, 156.52520454,\n",
              "       197.88796516, 167.57984206, 120.74478913,  84.83879727,\n",
              "       192.03728687, 160.60687024, 175.17178362,  84.22833237,\n",
              "       145.7995542 , 145.97333493, 140.96488953, 197.00421108,\n",
              "       165.94322494, 190.65906468, 128.22520508, 206.41941223,\n",
              "        84.35851196, 164.0256504 , 144.1056776 , 184.68355549,\n",
              "       177.80238966,  74.32855231, 143.3660286 , 138.67726085,\n",
              "       120.81146113, 234.34252077, 161.94390244,  74.5455476 ,\n",
              "       154.71905074, 156.78884927, 237.42227096, 174.23053048,\n",
              "       190.88212635, 118.98373473, 132.20418974, 168.52674824,\n",
              "       214.74245466, 171.42364091, 157.37409906, 108.86927343,\n",
              "       257.06329636, 152.17777143,  82.43686464, 231.56746032,\n",
              "       202.90641336,  47.18340199,  78.46954525, 129.30170908,\n",
              "       104.60253144, 144.65200281, 132.27974254, 190.04134164,\n",
              "        97.55541138, 197.51891007, 219.13709291, 186.13797012,\n",
              "       149.60913007, 208.42379455,  44.59036026, 206.20925368,\n",
              "        76.77377721,  94.94046865, 145.2955051 , 194.03776373,\n",
              "       132.78534336])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGXrS3pxRERp",
        "colab_type": "code",
        "outputId": "f80f00f9-9954-49c2-d90f-2bc90278650d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "# plot prediction and actual data\n",
        "y_pred = model.predict(X_test) \n",
        "plt.plot(y_test, y_pred, '.')\n",
        "\n",
        "# plot a line, a perfit predict would all fall on this line\n",
        "x = np.linspace(0, 330, 100)\n",
        "y = x\n",
        "plt.plot(x, y)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xl8VNX9//HXJwk7yi4iO4haNxBQ\noe4LLlRFq1Wse7G0VVxabetWxbrU8nWvWIvVKnWv6I9FVBaxVCsoQRQEl4AgIIuyKbImOb8/7g0N\nMZNMZrvLvJ+PRx6Z3Lkz88lk8p4z55x7rjnnEBGR+CoIugAREckuBb2ISMwp6EVEYk5BLyIScwp6\nEZGYU9CLiMScgl5EJOYU9CIiMaegFxGJuaKgCwBo3bq169KlS9BliIhESnFx8dfOuTa17ReKoO/S\npQuzZs0KugwRkUgxsyXJ7KeuGxGRmFPQi4jEnIJeRCTmFPQiIjGnoBcRiTkFvYhIzCnoRURiTkEv\nIhKEsu3wn3theXHWHyoUB0yJiOSVFR/A2GGw8kPYcjW075PVh1PQi4jkyvYtMH0EvHU/NG4FZ4+G\nfQdl/WEV9CIiufDFDK8Vv+Yz6PlTOPEOaNwyJw+toBcRyaatG2HqH+HdUdCsI5z/Eux5XE5LUNCL\niGRLyRQYfzVsWAaH/gKO/QM0aJrzMhT0IiKZtmktvH4jfPAMtN4LfvY6dDo0sHIU9CIimTR/LLxy\nLWxeC0dcC0f+Fuo1DLQkBb2ISCZ8uxImXgsLxkO7nnD+GGh3YNBVAQp6EZH0OAdznobXb/CmTx4/\nHPpfAYXhidfwVCIiEjXrFsP4q2DRm9CpP5z2ELTeM+iqvkdBLyJSV+Vl8O6jMPVWsAIYeDf0HQIF\n4VxVRkEvIlIXX33iHfi07F3YcwCcch807xh0VTVS0IuIJKNsO7x9P/x7BNRvAmeMggPPBrOgK6uV\ngl5EpDZfvu+14lfNg/1+DCePgKZtgq4qaQp6EZFEtm+GN/8E//0LNNkNBj8D+/wo6KrqrNagN7OG\nwHSggb//i865W8ysK/Ac0AooBi5wzm0zswbAaKAPsAY4xzm3OEv1i4hkx+K3YdwVsHYhHHQBnHA7\nNGoedFUpSWaIeCtwrHOuJ9ALOMnM+gF/Bu5zzu0JrAOG+PsPAdb52+/z9xMRiYYt38CE38ATA6G8\nFC4cC4MeimzIQxJB7zwb/R/r+V8OOBZ40d/+JHC6f3mQ/zP+9ceZRWC0QkTks8nwcH+Y9Tj0uwwu\newe6HR10VWlLqo/ezArxumf2BEYCC4H1zrlSf5dlQHv/cntgKYBzrtTMNuB173xd5T6HAkMBOnXq\nlN5vISKSjk1r4bXr4cPnoM0+MGQydDw46KoyJqmgd86VAb3MrDnwMrBPug/snBsFjALo27evS/f+\nRETqzDn46GWY+FvYsh6O+j0ccQ0UNQi6soyq06wb59x6M5sG9Aeam1mR36rvACz3d1sOdASWmVkR\n0AxvUFZEJDy+WQGvXAOfvAJ7HASnjYXd9w+6qqyotY/ezNr4LXnMrBEwAFgATAPO8ne7CBjrXx7n\n/4x//RvOObXYRSQcnIPiJ2HkobBwqjebZsiU2IY8JNeibwc86ffTFwAvOOcmmNl84Dkzux14H3jM\n3/8x4J9mVgKsBQZnoW4Rkbpb+zmMvxI+nw6dD4fTHoRW3YOuKutqDXrn3IfAQdVsXwQcUs32LcBP\nMlKdiEgmlJfBzEdg6m1QUASn3A+9LwrtImSZpiNjRSTeVs33DnxaPgt6nOgtQtasfe23ixEFvYjE\nU+k2eOtemH43NNwVznwM9j8zEouQZZqCXkTiZ3mxtwjZ6vmw/1lw8p+hSeugqwqMgl5E4mPbJnjz\nTnhnJDTdHc59DvY+OeiqAqegF5F4+Pw/3oyatYugz8Uw4I/QsFnQVYWCgl5Eom3LBph8CxT/A1p0\nhYvGQ9cjg64qVBT0IhJdn7wGE34NG1dC/2FwzI1Qv3HQVYWOgl5Eoue7r+HV38O8F2G3feGcp6BD\nn6CrCi0FvYhEh3Mwbwy8+jtv3fijr4fDfwNF9YOuLNQU9CISDRuWe4uQffoqtO8Dpz0EbfcNuqpI\nUNCLSLiVl8PsJ2HyzVC2HU68Ew79JRQUBl1ZZCjoRSS81iyE8VfB4v94M2lOfRBadg26qshR0ItI\n+JSVwoyHYdodUFjfC/jeF+bl8gWZoKAXkXBZ9ZG3fMGXs2HvgfCje2DXPYKuKtIU9CISDqVb4T/3\neF8Nm8NZ/4D9zlArPgMU9CISvGWzYOzl8NXHcOA5cNJd0Lhl0FXFhoJeRIKz7Tt44w6vP37X9nDe\ni9BjQNBVxY6CXkSCsehNGHclrF8CfYfA8cO9deNrUbxkHTMWraFft1b06dwi21XGgoJeQk//2DGz\neT1M/gPMHg0tu8PFE6HLYUndtHjJOs77+wy2lZZTv6iApy/tp9dEEhT0Emr6x46ZjyfCK7+Bjavg\nsKu8JQzqNUr65jMWrWFbaTnlDraXljNj0Rq9HpKgoJdQ0z92TGz8yluf5qOXoO3+MPgZaN+7znfT\nr1sr6hcVsL20nHpFBfTr1ioLxcZPrUFvZh2B0UBbwAGjnHMPmNlw4OfAV/6uNzjnJvq3uR4YApQB\nVzrnXs9C7ZIH9I8dcc7B3H95K01u2wjH3ASHXw2F9VK6uz6dW/D0pf3UlVdH5pyreQezdkA759xs\nM9sFKAZOB84GNjrn7q6y/77As8AhwB7AFGAv51xZosfo27evmzVrVlq/iMSX+ugjasMyb634zyZB\nh4O9Rch22yfoqmLFzIqdc31r26/WFr1zbgWwwr/8rZktANrXcJNBwHPOua3A52ZWghf67yRVuUgV\nfTq3UMDXUaBvjuXlUPw4TB4OrsybE3/IUC1CFqA69dGbWRfgIGAmcBgwzMwuBGYB1zjn1uG9Ccyo\ndLNlVPPGYGZDgaEAnTp1SqF0EalOoAPYaxbCuCtgydvQ7Wg49QFo0SU3jy0JFSS7o5k1BcYAVzvn\nvgH+CnQHeuG1+O+pywM750Y55/o65/q2adOmLjcVkRpUN4CddWWl8Nb98Ncfwqp5MGgkXPD/FPIh\nkVSL3szq4YX80865lwCcc6sqXf8oMMH/cTnQsdLNO/jbRCQHcj6AvXKut3zBig9gn1O8Rch22b3O\nd6OxmOxJZtaNAY8BC5xz91ba3s7vvwc4A5jnXx4HPGNm9+INxvYA3s1o1SKSUM5mpmzfAtP/D96+\nHxq1hLNHw76DUrorHS+RXcm06A8DLgDmmtkcf9sNwLlm1gtvyuVi4BcAzrmPzOwFYD5QClxe04wb\nEcm8rA9gfzETxg2Drz+Fnud6Z31KYxEyHS+RXcnMunkLqG6d0Ik13OYO4I406hKRMNq6Ed64DWb+\nDZp1gPPHwJ7Hp323cTxeIkxdUToyViQkwhQM1Vr4hndav/VfeNMlj7sZGuySkbuO24FQYeuKUtBL\n0kIfRBEWtmDYyeZ18PpNMOcpaNUDLnkNOvfP+MPE6XiJsHVFKeglKaEOohgIWzDsMH8cTLwWvvsa\nDv8NHPV7qNcwZw8f1cZF2LqiFPSSlNAGUUyELRj4dpUX8AvGwe4HwE9fgD165bSEKDYuKr8xhakr\nSkEvSQldEMVMaPqonYMPnoXXroftm+HYP3jLCae4CFk6ota4qO6N6fJj9gy6LEBBL0kKTRDFWOB9\n1Ou/gPFXw8Kp0LEfnPYXaLNXYOVErXER5jcmBb0kLfAgkuwoL4f3/g5ThoMZDLzbO7VfQdIrpGRF\n1BoXYX5jqnWZ4lzQMsUiAfnqU28RsqUzoPtxcOr90FyLDKYq14PHGVumWERiqGw7vP0A/PvPUK8x\nnP4I9BzsteglZWH91KugF8k3Kz7wFiFbOddbm2bg3dB0t6CrkixS0Ivki+2bvRb82w9Ck9Zw9j9h\n39OCrkpyQEEveSmbfamhPMhnyTveImRrSqDX+XDi7dAoJLVJ1inoJe9k80Cc0B3ks/VbmHIrvPco\nNOsEF7wM3Y8Nrh4JRLDzp/Jc8ZJ1jJxWQvGSdUGXkleyeQamQM7ulEjJFHi4vzd18tBfwmXvKOTz\nlFr0AQldyy+PZHO+cyjmUm9aC6/f4B3h2nov+Nnr0OnQ3NchoaGgD0iYj6KLu2weiBPoQT7Owfyx\n3ho1m9fBkb+FI67N6SJkEk4K+oCEouWXx7I53zmQudTfroRXroGPJ0C7nl5f/O4H5LYGCS0FfUCi\ndnh31IVyJkwmOAdznva6akq3wvG3Qv9hUKh/bfkfvRoCFNaj6OImiuMhSb0xrVvsnfFp0ZvQ6Yfe\nImStw7FaYpTEthFQiYJeYi9q4yG1vjGVl8G7o2DqH8EK4Uf3Qp9LAl+ELIqi2AhIRa2vDDPraGbT\nzGy+mX1kZlf521ua2WQz+8z/3sLfbmb2oJmVmNmHZtY727+E5J+6TE2tGA8pNCIxHlLjFM3VH8Pj\nJ8Fr10Hnw+DyGXBw8CtNRlWopsNmUTIt+lLgGufcbDPbBSg2s8nAxcBU59xdZnYdcB3we+BkoIf/\ndSjwV/+7SEbUtRUWtfGQagfqy7bDW/fD9BFQvyn8+FE44CdahCxN+TIpotagd86tAFb4l781swVA\ne2AQcLS/25PAm3hBPwgY7bz1j2eYWXMza+ffj0jaUumKidJ4yPfemIo+h1FXwKp5sN+P4eQR0LRN\n0GXGQtQaAamqUx+9mXUBDgJmAm0rhfdKoK1/uT2wtNLNlvnbFPQZlA8DSInkQyusT+cW9NmjIUy7\nE955CJq2hcHPwj4Dgy4tdqLUCEhV0kFvZk2BMcDVzrlvrNJHRuecM7M6ncHEzIYCQwE6ddKJDuoi\nXwaQEgmyFZbOG2ydbrv4Le+EIGsXQe8LYcBt0Kh5GpXHXz43fmqTVNCbWT28kH/aOfeSv3lVRZeM\nmbUDVvvblwMdK928g79tJ865UcAo8M4wlWL9eSlqs0iyIYhWWDpvsEnfdss3MOUWmPU4NO8MF46D\nbkdl+DeJn3xv/NQmmVk3BjwGLHDO3VvpqnHARf7li4CxlbZf6M++6QdsUP98ZkVtFkku5GKBuHRm\naCR1208nwcP9YNY/oN9l3iJkCvmk5MvsmVQl06I/DLgAmGtmc/xtNwB3AS+Y2RBgCXC2f91EYCBQ\nAmwCLsloxZI3A0jJylVrLp2xgUS3LV6yjjmflHD6qpG0WvgytNkHhkyGjgdnvP44y4dxm3To5OAS\nqEz0q46cVsI9kz6h3EGhwW9O2JvLj0nvCNFEdWWyj7548Vqeevw+brQnaMZ3fNXrcvY49SYoapBW\n7WGWdyd8yTKdHFxCL1Mt8Uy35mqqK52xgZ1u+80KWoz/BfcV/JsPyrtxQekNnNJ8AJeHIOSzFZjZ\n/uSVD7NnUqWgl8BkalA5011Zda2rTsHoHMweDZP+QJfSLYwoP4+/bz+JgqJ6oehuyGYY52ISQT62\n6pOhoJfAZLIlnsnWXF3qqlMwrv0cxl8Jn0+HzodTcNqDHLexJU0y3EWUjmyGcbb70TXzJjEFvQQm\nrIPKdakrqWAsL4OZj8DU26CgCE65H3pfBAUF9GnF9/YPMrCyGcbZ/ntr2nFiCnoJVFj7VZOtq9Zg\nXDXfO/Bp+SzY6yRvpclm7Wu8zyADK9thnM2/t2beJKagF0lDwmAs3QZv3QvT74aGu8KZj8H+Zya1\nCFnQgRXWN9/ahPUTYhhoeqVIGqrtS19eDGOHwer53gqTJ90FTVqnf78hFJU640rTK0WyrGpf+jMX\n96R3yUiY8TA03R3OfR72Piml+45Cq1qDn9GhoBdJUeW+9D5lc+n+r2thyzLvbE8DboWGzYIuMast\nbg1+RoeCXqSOKsKzReP6tCzawjU8xbmFb7ClXmc4ZwJ0PSLoEoHst7iDHkuQ5CnoJTBR7N+tHJ4n\nFL3P9MZP0nDr16zcfyi7n3Yr1G8cdIk7ZLvFnczgZxT/xnGkoJdARLV/d8aiNTQtXc8fikYzqPC/\nrCnqTuMLn2P39n2CLu17ctHirmksIap/4zhS0EsgItm/6xwn8xbn1r+JpmziwfKfcPiZd9Cqfdva\nbxuATEw3TKdFHsm/cUwp6CUQNbU2Q/lxf8NyeOU3dPv0Nb5r05MxXW7ksAMOoXdY6ksgndk76bbI\n1YcfHgp6CUSi1mY2P+6n9AZSXg6zn4TJN0PZdjjxTpoc+kvOLSjMSE1hlm6LXAcwhYeCXgJTXWuz\ncrhsy+DH/ZTeQNYshPFXweL/QNcj4dQHoWXXpB4rDuGWiRZ5FI4HyAcKesm4dIKuReP6lPsHa5c7\n7+dMSHSquWrrLCv1DnqadgcUNoDT/gIHXZDU8gVxGoAMc4s8Lm+muaKgl4xKN+jWbdqGAQ7vhMbr\nNm3LSF1VW6ctGtevvs6V82DcMPjyfdh7oLcI2a7tkn6cdLs7whZgYWyRx+nNNFcU9JJR6QZdv26t\naFAv8wN4VVunVet8t2QFfRY+7C1E1rA5nPUP2O+MpFrxVetPtbtDAZYczeapOwW9ZFS6/bpVAxm8\nc8JWHbBN1Oqt6bqqrdOKOvsWLeTiubfA+s/gwHO8Rcgat0zl10+ru0MBlhzN5qk7rV6Zx7J5btDK\nQZ3OybSrtnCBhK3euraI3y9Zjk27nZ7Ln8V2bQ+n3g89BqT4W6evov6KAFOLPrGwdXEFJWOrV5rZ\n48ApwGrn3P7+tuHAz4Gv/N1ucM5N9K+7HhgClAFXOudeT+k3kKzKZjdBRcs53cdINICaqNVbpxbx\nwmkcNOFKWP8F9B0Cxw/31o0PUJgHP8MmjGMHYZZM180TwEPA6Crb73PO3V15g5ntCwwG9gP2AKaY\n2V7OubIM1CoZlItugkz011f3ET3Rx/akPtJvXg+TboT3n4KW3eHiidDlsLR/10xRgIVD3D4x1Br0\nzrnpZtYlyfsbBDznnNsKfG5mJcAhwDspVyhZkYt+zkz311f8w1XdVrxkHS/NXoYDbj5lP9Zt2lb9\nP+iCCfDKNfDdavjhlXDMDVCvUYZ+W4mLOA6KpzMYO8zMLgRmAdc459YB7YEZlfZZ5m+TkMlFN0Em\nHqO6Fm7lbcVL1nHuo94/JUD9QuPZof13vs3Gr+DV38JHL0Pb/eHcZ6F979R/MYm1OA6Kpxr0fwVu\nw5vufBtwD/CzutyBmQ0FhgJ06tQpxTIkHbnoJsj2Y8xYtIbtfsgDbC9z//vHdA4+fAFe+z1s+w6O\nvQkOuxoK62WtnkyLWxdCFMRxVk9KQe+cW1Vx2cweBSb4Py4HOlbatYO/rbr7GAWMAm/WTSp1SObU\nNVDCEkD9urWiXlHBjhZ9vULz/jHXL4UJv4aSydDhEBj0ELTZO+XHCeL3jWMXQhTEcVA8paA3s3bO\nuRX+j2cA8/zL44BnzOxevMHYHsC7aVcpWZUoUBKFW5gCqE/nFjz78347+ujPPGgP+qx6EZ4e7rXo\nTx4BB18KaSxCFtTvm2oXQljehKMsboPiyUyvfBY4GmhtZsuAW4CjzawXXtfNYuAXAM65j8zsBWA+\nUApcrhk34ZdoGmOicAtbH+aOf8qvS2Dc+fDFf6HbMXDqA9Cic9r3H9Tvm0oXQqJjDxT8+S2ZWTfn\nVrP5sRr2vwO4I52iJLeqC5Sawi10fZhlpfDOX+DNu6CoAQx6GHr9tM7LFyQS1O+bShdC1b/bS7OX\nMWb2slB8+pLgaAkESRgoicItVH2YK+fC2MthxQfwg1Nh4D2wS2bP+JTq75uJLpS6diFUfVNyJD7A\nTPKHlkCQhELd17t9C0z/P3j7fmjUEn50N+w7KOiqdghyHKPqEhRaViG+MrYEguSv0A5IfTHTW0r4\n60+h50/hxDtSXoQsW4Icx6j6dwvNpy8JjII+pELdmg7K1o0w9Y/w7iho1gHOHwN7Hh90VdUK0zhG\naN+wJWcU9CFU28f+vHwTKJkK46+GDUvhkJ/DcTdDg12CriqhUI1j1EFevrbygII+hGr62B+mOew5\nsXkdvH4jzHkaWvWAS16Fzv0DK6cuQRi1lnTevbbyiII+ALWFRU0f+8M2hz2r5o+DidfCd1/DEdfA\nkb+Deg0DKyfuQZhXr608o6DPsWTCoqaP/WHq+82ab1d5Ab9gHOx+AJz3L2jXM+iqYh+EefHaylMK\n+hxLNiwSfeyPat9vUpyDD56F166H7ZvhuFvgh1eEZhGyuAdhrF9beU5Bn2OZCIuo9f0mZd0SmHA1\nLHwDOvbzFiFr3SPoqnaSD0EYy9eW6ICpIGhmQyXl5fDe32HKcG/JguOHe6f2KygIuDCR8NMBUyGW\nSqspk28OmbivjNTz1acw7gpYOsObD3/KfdBc5yYQyTQFfchVnCbvX7OWUlru0p7tkYmZI2nfR9l2\nePsB+PefoX4TOONvcOA5GVuETER2pqAPsYpA3bq9nIoOtnRne2Ri5kha9/HlHG/5gpVzvbVpBt4N\nTXdL4TcRkWQp6EOsIlArQt4g7dkemRgMTuk+tm/2WvBvPwhNWsM5T3mrTYpI1inoQ6xyoBYWFnBW\nnw6c2btDWn30mTphd53uY8k7Xit+TQn0Oh9OvB0axXcQWoPtEjaadRNykQ6Nrd/ClFvhvUe9QdZT\nH4TuxwRdVVbF/ehZCRfNuomJyM5r/myKNy9+wzI49Fdw7E3QoGnQVWVd3I+elWhS0EtGVHzyOGyP\nAnrNH+Ed4dp6bxgyCToekvL9Re2TTNyPnpVoUtBL2rzuinc4rnwG5xQ9gSv4DjviWjjqd945XFO6\nv2h2f+TD0bMSPQp6Sbv1/OGCj3mAezmx3nvMLe/KlN6PMPi4gSnXE/Xuj8h2t0ls1Rr0ZvY4cAqw\n2jm3v7+tJfA80AVYDJztnFtnZgY8AAwENgEXO+dmZ6d0yYS0Ws/OwftPccHs6ykt2MJdpefyTzuF\n0Qemt168uj9EMiuZFv0TwEPA6ErbrgOmOufuMrPr/J9/D5wM9PC/DgX+6n+XkEq59bxuMYy/Cha9\nSVHnw/i4z23ssqYZozPQXaHuD5HMqjXonXPTzaxLlc2DgKP9y08Cb+IF/SBgtPPmbM4ws+Zm1s45\ntyJTBUtm1bn1XF7G0tfuZ/dZIygoKKTwR/dAn5+xf0EB+2ewLnV/iGROqn30bSuF90qgrX+5PbC0\n0n7L/G0K+pCqU+t59cds/Nev6PjVbN4s68nN5T/niGW9+PFuGxTKIiGW9mCsc86ZWZ2PujKzocBQ\ngE6dtGJhkGptPZdu8xYhmz6CQmvEr7dfxstlhwHGMzO/YMzsZZGaGSOSb1Jd9HuVmbUD8L+v9rcv\nBzpW2q+Dv+17nHOjnHN9nXN927Rpk2IZ0VS8ZB0jp5VQvGRd0KXUbvlsePQYmHY7/OBUPj1rKq8W\nHInhrTTp+F/fvoiEU6ot+nHARcBd/vexlbYPM7Pn8AZhN6h/fmeRmSO+fTNMuxPeeQia7AaDn4V9\nBtITePrS1oyZvYwXi5dRVqaZMSJhl8z0ymfxBl5bm9ky4Ba8gH/BzIYAS4Cz/d0n4k2tLMGbXnlJ\nFmqOtGzPEc/IEaWL3/JOCLJ2EfS+EAbcBo2a77i6oqvnzN4dNDNGJAKSmXVzboKrjqtmXwdcnm5R\ncZbNOeJpf1rY8g1MuQVmPQ4tusCFY6Hb0Ql318wYkWjQkbE5ls054ml9Wvj0dZjwa/h2BfQfBsfc\nCPUbZ6w2EQmOgj5GUvq08N0aeO06mPsCtPkBnD0aOtS66qmIRIiCPseyORhbp08LzsG8MfDq77wu\nm6OugyOugaL6O/XzA+qHT0FUV9+UeFLQ51i2B2OT6jf/5kt45Rr4ZCLs0RsGPQRt9wN2fiMqKjAw\no7Qs5DOEQiYyM6skb6Q6j15SVNG9Umje+V9bNK6fuzn1zkHxkzCyHyycBifcAZdO2RHyUOWNqMyx\nvcqbktSuujdzkSCpRZ9jlbtXWjSuzx8nfJSblt/aRTDuSlj8H+hyBJz6ALTq/r3ddjpPrd+i11z5\nutHqmxI2CvoAVHSvjJxWkv1118vLYOYjMPU2KKwHp9wPvS+Cguo/zFXt5wd2vClVtEzVDVEzrb4p\nYaOgD1DWW36r5sO4YbC8GPY6CX50LzRrX+vNquvnr67PWQOOiekYAwkTBX2AstbyK90Gb90L0++G\nhrvCmY/B/meCWcKb1BTaifqcgx5w1BuNSHIU9AHLeMtvWbHXil89Hw74CZx0FzRpXeNNapslUt0n\nj6BP96eZLSLJU9DHxbZNMO0OmPEwNN0dzn0e9j4pqZvWFtqJPnkEOeAY9BuNSJQo6OPg8+neImTr\nFkOfS2DArdCwWdI3T2asoOonj6AHHDWzRSR55q1DFqy+ffu6WbNmBV1G9GzZAJP+ALOfhJbd4NQH\noesRKd1VFPu7o1izSCaZWbFzrtY1S9Sij6pPXvUWIdu4Cn54JRx9/Y5FyFIJwCjOEolizSJBUNBH\nzXdfe+vTzBsDu+0Hg5+B9r13XK1BShGpSkEfFc7B3Be9kN/6LRx9Axz+ayiqv9NuGqQUkaoU9FGw\nYbnXTfPZ69C+r7cI2W4/qHZXDVKKSFUK+jArL4fZT8Ckm8GVwYl3wqG/hILChDcJejaMiISPgj6s\n1iz0FiFb8hZ0PcpbhKxl16RuqkFKEalMQR82ZaUwYyRMuxMKG8BpD8FB59e4fIGISE0U9GGycp63\nfMGX78M+p8DAu2HXdkFXJSIRl1bQm9li4FugDCh1zvU1s5bA80AXYDFwtnMuB2fViLDSrd4CZG/d\nC41awE+egH1PVyteRDIiE2eYOsY516vS0VnXAVOdcz2Aqf7PksjS9+BvR8L0Ed4iZJe/C/udoZAX\nkYzJRtfNIOBo//KTwJvA77PwONG27TvvZCAzH4Fd28N5L0KPAUFXJSIxlG7QO2CSmTngb865UUBb\n59wK//qVQNs0HyN+Fk6D8VfB+iVw8M/h+FugwS5BVyUiMZVu0B/unFtuZrsBk83s48pXOuec/ybw\nPWY2FBgK0KlTpzTLiIjN62HSjfD+U9CyO1zyKnT+4U67aKEuEcm0tILeObfc/77azF4GDgFWmVk7\n59wKM2sHrE5w21HAKPBWr0ynjkhYMIFt435N0eY1rDrgV7Q77Rao12inXbROjYhkQ8qDsWbWxMx2\nqbgMnADMA8YBF/m7XQSMTbdaTEqtAAAIK0lEQVTISNu4Gl64CJ4/j4WbGnH6tls5Zs5RFH+55Xu7\nJjpln4hIOtJp0bcFXjZvdkgR8Ixz7jUzew94wcyGAEuAs9MvM4Kcgw+fh9eug23fMaPL5Vz4yaFs\nc0UUuuoXG9M6NSKSDSkHvXNuEdCzmu1rgOPSKSry1i/1FiErmQwdDoFBD1Fv024ULJxBYS1ncdI6\nNSKSaToyNpPKy2HWYzBluNeiP3kEHHwpFBTSB5IKca1TIyKZpqDPlK8/8xYh++K/0O0YbxGyFp13\n2kUhLiJBUNCnq6wU3vkLTPsT1GsIgx6GXj/Vka0iEhoK+nSs+NBbhGzFB/CDU2HgPbCLjg8TkXBR\n0Kdi+xZvbZq37ofGreDs0bDvoKCrEhGploK+rr6YAWOHwZrPoNd5cMLt0Lhl0FWJiCSkoE/W1o0w\n9Y/w7iho1hHOfwn2zO9ZpCISDQr6ZJRMhfFXw4alcMhQOO5maNA06KpERJKioK/JprUw6SaY8zS0\n6gE/ew069Qu6KhGROlHQJzJ/LLxyLWxaA0dcA0f+zps+KSISMQr6qr5dBROvgQXjYfcD4fwx0O7A\noKsSEUmZgr6CczDnGXj9em/65PHDof8VUKinSESiTSkGsG4JTLgaFr4BnfrDaX+B1j2CrkpEJCPy\nO+jLy+G9R2HKrd6SBQPvhr5DoCAT50wXEQmH/A36rz71li9YOhP2PB5OuQ+a58kpDUUkr+Rf0Jdt\nh7cfgH//Geo3gdMfgZ6DtQiZiMRWfgX9l3O8VvzKubDv6TDw/6DpbkFXJSKSVfkR9Ns3ey34tx+E\nJq3hnKe81SZFRPJA/IN+yX9h3BWwpgQOOt9bhKyRTv4hIvkjvkG/5RuYeiu893dvkPWCl6H7sUFX\nJSKSc/EM+s8me4uQfbMc+l0Gx97kDbyKiOShrE0YN7OTzOwTMysxs+uy9Tg72bQWXvoFPH2Wt7rk\nkElw0p8U8iKS17LSojezQmAkMABYBrxnZuOcc/Oz8Xg4Bx+9DBN/C1vWewuQHXktFDXIysOJiERJ\ntrpuDgFKnHOLAMzsOWAQkPmg/2YFTLwWPp4A7XrBhWNh9/0z/jAiIlGVraBvDyyt9PMy4NCMP8qn\nk2DMpVC2FQbc5vXHaxEyEZGdBJaKZjYUGArQqVOKSw+06g4dD4aTR3iXRUTke7I1GLsc6Fjp5w7+\nth2cc6Occ32dc33btGmT2qO06u6tF6+QFxFJKFtB/x7Qw8y6mll9YDAwLkuPJSIiNchK141zrtTM\nhgGvA4XA4865j7LxWCIiUrOs9dE75yYCE7N1/yIikhydYUNEJOYU9CIiMaegFxGJOQW9iEjMKehF\nRGLOnHNB14CZfQUsSfHmrYGvM1hOLkW1dtWdW6o7t6JUd2fnXK1HnIYi6NNhZrOcc32DriMVUa1d\ndeeW6s6tqNZdE3XdiIjEnIJeRCTm4hD0o4IuIA1RrV1155bqzq2o1p1Q5PvoRUSkZnFo0YuISA0i\nHfSBnIA8RWa22MzmmtkcM5vlb2tpZpPN7DP/e4sQ1Pm4ma02s3mVtlVbp3ke9J//D82sd8jqHm5m\ny/3nfI6ZDax03fV+3Z+Y2YnBVA1m1tHMppnZfDP7yMyu8reH+jmvoe5QP+dm1tDM3jWzD/y6b/W3\ndzWzmX59z/vLq2NmDfyfS/zruwRRd9qcc5H8wlv+eCHQDagPfADsG3RdNdS7GGhdZdsI4Dr/8nXA\nn0NQ55FAb2BebXUCA4FXAQP6ATNDVvdw4Npq9t3Xf700ALr6r6PCgOpuB/T2L+8CfOrXF+rnvIa6\nQ/2c+89bU/9yPWCm/zy+AAz2tz8C/Mq/fBnwiH95MPB8EM93ul9RbtHvOAG5c24bUHEC8igZBDzp\nX34SOD3AWgBwzk0H1lbZnKjOQcBo55kBNDezdrmpdGcJ6k5kEPCcc26rc+5zoATv9ZRzzrkVzrnZ\n/uVvgQV451wO9XNeQ92JhOI595+3jf6P9fwvBxwLvOhvr/p8V/wdXgSOMzPLUbkZE+Wgr+4E5DW9\n0ILmgElmVuyfLxegrXNuhX95JdA2mNJqlajOKPwNhvldHI9X6hoLZd1+t8BBeK3MyDznVeqGkD/n\nZlZoZnOA1cBkvE8X651zpdXUtqNu//oNQKvcVpy+KAd91BzunOsNnAxcbmZHVr7SeZ8NQz8FKip1\n+v4KdAd6ASuAe4ItJzEzawqMAa52zn1T+bowP+fV1B3659w5V+ac64V3LutDgH0CLinrohz0tZ6A\nPEycc8v976uBl/FeYKsqPnb731cHV2GNEtUZ6r+Bc26V/09dDjzK/7oKQlW3mdXDC8unnXMv+ZtD\n/5xXV3dUnnMA59x6YBrQH68LrOKMe5Vr21G3f30zYE2OS01blIM+MicgN7MmZrZLxWXgBGAeXr0X\n+btdBIwNpsJaJapzHHChPxOkH7ChUndD4Kr0XZ+B95yDV/dgf0ZFV6AH8G6u6wNvFg3wGLDAOXdv\npatC/Zwnqjvsz7mZtTGz5v7lRsAAvPGFacBZ/m5Vn++Kv8NZwBv+J6xoCXo0OJ0vvBkIn+L1sd0Y\ndD011NkNb8bBB8BHFbXi9fVNBT4DpgAtQ1Drs3gfubfj9VUOSVQn3gyGkf7zPxfoG7K6/+nX9SHe\nP2y7Svvf6Nf9CXBygHUfjtct8yEwx/8aGPbnvIa6Q/2cAwcC7/v1zQNu9rd3w3vjKQH+BTTwtzf0\nfy7xr+8W1GslnS8dGSsiEnNR7roREZEkKOhFRGJOQS8iEnMKehGRmFPQi4jEnIJeRCTmFPQiIjGn\noBcRibn/D5Ro++r220GwAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKD5jfdSDoKD",
        "colab_type": "code",
        "outputId": "c43ab40e-f7e1-419c-e5e9-8ee7ef8945a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "print('Coefficients: \\n', model.coef_)\n",
        "# The mean squared error\n",
        "print(\"Mean squared error: %.2f\"\n",
        "      % mean_squared_error(y_test, y_pred))\n",
        "# Explained variance score: 1 is perfect prediction\n",
        "print('Variance score: %.2f' % r2_score(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Coefficients: \n",
            " [ -35.55683674 -243.1692265   562.75404632  305.47203008 -662.78772128\n",
            "  324.27527477   24.78193291  170.33056502  731.67810787   43.02846824]\n",
            "Mean squared error: 3424.32\n",
            "Variance score: 0.33\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHso7DpzyXVV",
        "colab_type": "text"
      },
      "source": [
        "# Overfitting and Underfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8VSoy-gyu6I",
        "colab_type": "text"
      },
      "source": [
        "Underfitting is when models does not perform well on the training data of the test data. It is not able to capture the actual relationship between the features and the output, and instead has a strong preconcieved notion of what the relatioinship is."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8obB7hMQsAo",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://miro.medium.com/max/1564/1*Gl5dciQc0H72vnZr5vIGqA.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKxednsNQ9tr",
        "colab_type": "text"
      },
      "source": [
        "Overfitting is when models perform very well on the training data but perform poorly on the test data. The model is able to fit training points very closely,  but cannot generalize well to new examples because it has learned a relationship that is overly complex and overly specialized to the training set. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5h9Ov0N1SS6L",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://ardianumam.files.wordpress.com/2017/09/overfitting1.jpg)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jP0fRi81RgSe",
        "colab_type": "code",
        "outputId": "b4c51dfb-ca3c-4ca2-de16-48bd168faa3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"Testing accuracy: \", model.score(X_test, y_test))\n",
        "print(\"Training accuracy: \", model.score(X_train, y_train))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing accuracy:  0.33222203269065176\n",
            "Training accuracy:  0.5539285357415583\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLAcct1JSAi3",
        "colab_type": "text"
      },
      "source": [
        "Our testing accuracy and training accuracy are both pretty low. That may be a sign that our model has underfit the training data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuOV1NHnUIgA",
        "colab_type": "text"
      },
      "source": [
        "One way we can reduce underfitting is by adding on polynomial features, meaning we take on of our features, square it, or cube it, or multiply with another feature, and then add that as another data column. That way, our model has essentially more to go off of when it learns. Here, PolynomialFeatures is a tool provided by the sklearn library that can easily create those polynomial features for us, and we can easily select the degree we want. Right now, we are using a degree of two, which is a quadratic fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuHT3M94UZiZ",
        "colab_type": "code",
        "outputId": "9d403f51-3c38-4dfd-b4ef-a5bb29bdf821",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "poly = PolynomialFeatures(degree = 2)\n",
        "poly_features = poly.fit_transform(diabetes.data[:, 0:3])\n",
        "poly_features = np.delete(poly_features, (0, 1, 2), 1)\n",
        "poly_data = np.concatenate((diabetes.data, poly_features), axis = 1)\n",
        "print(poly_data.shape)\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(poly_data, diabetes.target, test_size=0.2, random_state=0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(442, 17)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2rfpcj1frxY",
        "colab_type": "code",
        "outputId": "4ed888f8-fc5a-4ba3-fb08-2ffccb359f8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model.fit(X_train2, y_train2)\n",
        "print(model.score(X_test2, y_test2))\n",
        "print(model.score(X_train2, y_train2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.35292669507760577\n",
            "0.5794148059518287\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vw-uaoCbiH76",
        "colab_type": "text"
      },
      "source": [
        "We are doing marginally better. We essentially did this to our model. We turned the linear fit into a quadratic fit.\n",
        "![This is not our data](https://animoidin.files.wordpress.com/2018/07/polim_vs_linear.jpg?w=909&h=584&crop=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVpclFmWjREO",
        "colab_type": "text"
      },
      "source": [
        "The degree of two was one I randomly selected. What happens if I select a degree of 8?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmklfQWvjoce",
        "colab_type": "code",
        "outputId": "45cf2902-9d8f-4e03-e5cd-85e98ee6c1cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "poly = PolynomialFeatures(degree = 8)\n",
        "poly10_features = poly.fit_transform(diabetes.data[:, 0:3])\n",
        "poly10_features = np.delete(poly10_features, (0, 1, 2), 1)\n",
        "poly10_data = np.concatenate((diabetes.data, poly10_features), axis = 1)\n",
        "print(poly10_data.shape)\n",
        "X_train10, X_test10, y_train10, y_test10 = train_test_split(poly10_data, diabetes.target, test_size=0.2, random_state=0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(442, 172)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uc8ttoGxkAQv",
        "colab_type": "code",
        "outputId": "1d650db8-6ea6-4161-a9bc-235c7840bc1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model.fit(X_train10, y_train10)\n",
        "print(model.score(X_train10, y_train10))\n",
        "print(model.score(X_test10, y_test10))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6486828967643996\n",
            "0.18729864038150798\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UWi0H0H8IOc",
        "colab_type": "text"
      },
      "source": [
        "Here we can see that the score on the training set is better, but the score on the test set is a lot worse. This is what we were just talking about, overfitting. Clearly the degree of the polynomial we choose has a lot to do with whether our model will underfit or overfit. But we can't just keep trying random degrees until we hit the right one. That's why we'll use cross validation instead."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_myO5qHiymsO",
        "colab_type": "text"
      },
      "source": [
        "#Cross Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFF7dZXSjBGu",
        "colab_type": "text"
      },
      "source": [
        "We discussed overfitting above. It is a common problem in machine learning where models seem to be achieving very high accuracy when training, but then just completely fail in real world settings. This is probably because the model is overfitting to the data and instead of forming a general function that relates diabetes to some attributes (age, bmi, sex, etc.), the model is \"cheating\" and just adjusting to random noise in the data.\n",
        "\n",
        "In essence we want to see how well the model will perform in the real world.  In the real world, the model receives data it has never seen before and it is asked to make predictions about this data.  So the only real way to assess the accuracy of your model is to test it on data it has never seen before. This is what cross validation is. There are many different methods of cross validation, but today we will be discussing the most basic one called the  \"holdout\" method.\n",
        "\n",
        "When we originally receive some data, we keep some aside that we will test the model on in the end. This is the \"test\" set.  Most of the data will be used to train the model so it is the  \"train\" set.  \n",
        "\n",
        "\n",
        "![alt text](https://miro.medium.com/max/2840/1*-8_kogvwmL1H6ooN1A1tsQ.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P-oeFORJqI_v",
        "outputId": "539d9135-a08d-4f5d-916f-0bd79843b2b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(diabetes.data, diabetes.target, test_size=0.2, random_state=0)\n",
        "print(diabetes.data.shape)\n",
        "X_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(442, 10)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(353, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQ9FvNnuqhe5",
        "colab_type": "text"
      },
      "source": [
        "This is what this line of code is doing above. It is splitting the original data into train sets and test sets. If you noticed the shape of the original dataset, it has 442 rows.  In the train_test_split, we specify that the test_size is 0.2.  This means 20% of the data is given to the test set and 80% is set aside for the training set. So when we call X_train.shape, we see that the  training set has 353 rows,  which  is 80% of 442!\n",
        "\n",
        "Another thing to note is when you are splitting the original data, you must randomize the rows you are selecting for training and testing so the model is training and testing on diverse data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvNxFjN_tPLg",
        "colab_type": "code",
        "outputId": "575fee8f-3a57-4c9b-ae16-1ac7099e3384",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "print(model_final.score(X_train, y_train))\n",
        "print(model_final.score(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-4b49cb58c813>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_final\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_final\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregression\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_check_reg_targets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m         \u001b[0;31m# XXX: Remove the check in 0.23\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_reg_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \"\"\"\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'coo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         return safe_sparse_dot(X, self.coef_.T,\n\u001b[0;32m--> 206\u001b[0;31m                                dense_output=True) + self.intercept_\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: shapes (353,10) and (172,) not aligned: 10 (dim 1) != 172 (dim 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3ly3-JFu9Ug",
        "colab_type": "text"
      },
      "source": [
        "As we see here, the test score is significantly lower than the train score showing that our original model did overfit.  This is to be expected, since we didn't add anything to our model to prevent it from overfitting. But at least we know what the true score of this model will be in the real world and we can work to improve it, rather than getting false high hopes by just going off of the training score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zAyq75_TiGon"
      },
      "source": [
        "#Video!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1U4Fzb7idCW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import YouTubeVideo\n",
        "YouTubeVideo('JMLsHI8aV0g')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}